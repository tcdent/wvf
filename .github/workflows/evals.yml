name: Run Worldview Evaluations

on:
  # Manual trigger with options
  workflow_dispatch:
    inputs:
      models:
        description: 'Models to evaluate (comma-separated, e.g., claude-sonnet,gpt-4o, or "all")'
        required: false
        default: 'all'
      difficulty:
        description: 'Difficulty level (baseline, moderate, extreme, or all)'
        required: false
        default: 'all'

  # Run after build workflow completes on PR
  workflow_run:
    workflows: ["Build Worldview Tools"]
    types: [completed]
    branches: [main, master]

jobs:
  evaluate:
    runs-on: ubuntu-latest
    # Only run if build succeeded (or if manually triggered)
    if: ${{ github.event_name == 'workflow_dispatch' || github.event.workflow_run.conclusion == 'success' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # For workflow_run, checkout the commit that triggered the build
          ref: ${{ github.event.workflow_run.head_sha || github.sha }}

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'evals/requirements.txt'

      - name: Install dependencies
        run: |
          pip install -r evals/requirements.txt

      - name: Download Worldview tools from build
        if: ${{ github.event_name == 'workflow_run' }}
        uses: actions/download-artifact@v4
        with:
          name: worldview-tools
          path: ./bin
          run-id: ${{ github.event.workflow_run.id }}
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Download Worldview tools (manual trigger)
        if: ${{ github.event_name == 'workflow_dispatch' }}
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: build.yml
          name: worldview-tools
          path: ./bin
        continue-on-error: true

      - name: Make tools executable
        run: |
          if [ -d "./bin" ] && [ -n "$(ls -A ./bin 2>/dev/null)" ]; then
            chmod +x ./bin/*
            echo "${{ github.workspace }}/bin" >> $GITHUB_PATH
            echo "CLI_AVAILABLE=true" >> $GITHUB_ENV
          else
            echo "CLI_AVAILABLE=false" >> $GITHUB_ENV
          fi

      - name: Parse model list
        id: models
        run: |
          MODELS="${{ github.event.inputs.models || 'all' }}"
          if [ "$MODELS" == "all" ]; then
            echo "use_all=true" >> $GITHUB_OUTPUT
            echo "list=" >> $GITHUB_OUTPUT
          else
            # Convert comma-separated to space-separated
            MODELS_SPACE="${MODELS//,/ }"
            echo "use_all=false" >> $GITHUB_OUTPUT
            echo "list=${MODELS_SPACE}" >> $GITHUB_OUTPUT
          fi

      - name: Run evaluations
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          mkdir -p results

          # Build command
          CMD="python -m evals run --verbose --output results"

          # Add models
          if [ "${{ steps.models.outputs.use_all }}" == "true" ]; then
            CMD="$CMD --all-models"
          else
            CMD="$CMD --models ${{ steps.models.outputs.list }}"
          fi

          # Add difficulty filter if not 'all'
          DIFFICULTY="${{ github.event.inputs.difficulty || 'all' }}"
          if [ "$DIFFICULTY" != "all" ]; then
            CMD="$CMD --difficulty $DIFFICULTY"
          fi

          # Add CLI flag if tools are available
          if [ "$CLI_AVAILABLE" == "true" ]; then
            CMD="$CMD --use-cli --worldview-cli ./bin/worldview"
          fi

          echo "Running: $CMD"
          $CMD

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: eval-results-${{ github.run_number }}
          path: results/
          retention-days: 30

      - name: Post summary
        run: |
          echo "## Worldview Evaluation Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          cat results/report.md >> $GITHUB_STEP_SUMMARY

      - name: Check for failures
        run: |
          # Extract success rate from JSON and fail if below threshold
          python -c "
          import json
          with open('results/results.json') as f:
              data = json.load(f)

          total_success = 0
          total_cases = 0

          for model, info in data['models'].items():
              total_success += info['summary']['success']
              total_cases += info['summary']['total']

          rate = total_success / total_cases if total_cases > 0 else 0
          print(f'Overall success rate: {rate:.1%}')

          # Baseline cases should always pass
          for model, info in data['models'].items():
              baseline_rate = info['summary']['baseline_rate']
              if baseline_rate < 0.8:
                  print(f'WARNING: {model} baseline rate {baseline_rate:.1%} is below 80%')
          "
