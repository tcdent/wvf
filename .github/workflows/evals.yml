name: Run Worldview Evaluations

on:
  # Manual trigger with options
  workflow_dispatch:
    inputs:
      models:
        description: 'Models to evaluate (comma-separated, e.g., claude-sonnet,gpt-4o, or "all")'
        required: false
        default: 'all'
      difficulty:
        description: 'Difficulty level (baseline, moderate, extreme, or all)'
        required: false
        default: 'all'
      eval_type:
        description: 'Evaluation type'
        required: false
        default: 'both'
        type: choice
        options:
          - read
          - write
          - both
      write_complexity:
        description: 'Write eval complexity (simple, moderate, complex, or all)'
        required: false
        default: 'all'

  # Run after build workflow completes on PR
  workflow_run:
    workflows: ["Build Worldview Tools"]
    types: [completed]
    branches: [main, master]

jobs:
  evaluate-read:
    runs-on: ubuntu-latest
    # Only run if build succeeded (or if manually triggered) and eval_type includes read
    if: |
      (github.event_name == 'workflow_dispatch' && github.event.inputs.eval_type != 'write') ||
      (github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success')

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # For workflow_run, checkout the commit that triggered the build
          ref: ${{ github.event.workflow_run.head_sha || github.sha }}

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'evals/requirements.txt'

      - name: Install dependencies
        run: |
          pip install -r evals/requirements.txt

      - name: Download Worldview tools from build
        if: ${{ github.event_name == 'workflow_run' }}
        uses: actions/download-artifact@v4
        with:
          name: worldview-tools
          path: ./bin
          run-id: ${{ github.event.workflow_run.id }}
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Download Worldview tools (manual trigger)
        if: ${{ github.event_name == 'workflow_dispatch' }}
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: build.yml
          name: worldview-tools
          path: ./bin
        continue-on-error: true

      - name: Make tools executable
        run: |
          if [ -d "./bin" ] && [ -n "$(ls -A ./bin 2>/dev/null)" ]; then
            chmod +x ./bin/*
            echo "${{ github.workspace }}/bin" >> $GITHUB_PATH
            echo "CLI_AVAILABLE=true" >> $GITHUB_ENV
          else
            echo "CLI_AVAILABLE=false" >> $GITHUB_ENV
          fi

      - name: Parse model list
        id: models
        run: |
          MODELS="${{ github.event.inputs.models || 'all' }}"
          if [ "$MODELS" == "all" ]; then
            echo "use_all=true" >> $GITHUB_OUTPUT
            echo "list=" >> $GITHUB_OUTPUT
          else
            # Convert comma-separated to space-separated
            MODELS_SPACE="${MODELS//,/ }"
            echo "use_all=false" >> $GITHUB_OUTPUT
            echo "list=${MODELS_SPACE}" >> $GITHUB_OUTPUT
          fi

      - name: Run evaluations
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          mkdir -p results

          # Build command
          CMD="python -m evals run --verbose --output results"

          # Add models
          if [ "${{ steps.models.outputs.use_all }}" == "true" ]; then
            CMD="$CMD --all-models"
          else
            CMD="$CMD --models ${{ steps.models.outputs.list }}"
          fi

          # Add difficulty filter if not 'all'
          DIFFICULTY="${{ github.event.inputs.difficulty || 'all' }}"
          if [ "$DIFFICULTY" != "all" ]; then
            CMD="$CMD --difficulty $DIFFICULTY"
          fi

          # Add CLI flag if tools are available
          if [ "$CLI_AVAILABLE" == "true" ]; then
            CMD="$CMD --use-cli --worldview-cli ./bin/worldview"
          fi

          echo "Running: $CMD"
          $CMD

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: eval-results-${{ github.run_number }}
          path: results/
          retention-days: 30

      - name: Post summary
        run: |
          echo "## Worldview Evaluation Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          cat results/report.md >> $GITHUB_STEP_SUMMARY

      - name: Check for failures
        run: |
          # Extract success rate from JSON and fail if below threshold
          python -c "
          import json
          with open('results/results.json') as f:
              data = json.load(f)

          total_success = 0
          total_cases = 0

          for model, info in data['models'].items():
              total_success += info['summary']['success']
              total_cases += info['summary']['total']

          rate = total_success / total_cases if total_cases > 0 else 0
          print(f'Overall success rate: {rate:.1%}')

          # Baseline cases should always pass
          for model, info in data['models'].items():
              baseline_rate = info['summary']['baseline_rate']
              if baseline_rate < 0.8:
                  print(f'WARNING: {model} baseline rate {baseline_rate:.1%} is below 80%')
          "

  evaluate-write:
    runs-on: ubuntu-latest
    # Only run if build succeeded and eval_type includes write (requires CLI tools)
    if: |
      (github.event_name == 'workflow_dispatch' && github.event.inputs.eval_type != 'read') ||
      (github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success')

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.workflow_run.head_sha || github.sha }}

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'evals/requirements.txt'

      - name: Install dependencies
        run: |
          pip install -r evals/requirements.txt

      - name: Download Worldview tools from build
        if: ${{ github.event_name == 'workflow_run' }}
        uses: actions/download-artifact@v4
        with:
          name: worldview-tools
          path: ./bin
          run-id: ${{ github.event.workflow_run.id }}
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Download Worldview tools (manual trigger)
        if: ${{ github.event_name == 'workflow_dispatch' }}
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: build.yml
          name: worldview-tools
          path: ./bin
        continue-on-error: true

      - name: Check CLI availability
        id: cli-check
        run: |
          if [ -d "./bin" ] && [ -f "./bin/worldview" ]; then
            chmod +x ./bin/*
            echo "${{ github.workspace }}/bin" >> $GITHUB_PATH
            echo "available=true" >> $GITHUB_OUTPUT
          else
            echo "available=false" >> $GITHUB_OUTPUT
            echo "::warning::Worldview CLI not available, skipping write evaluations"
          fi

      - name: Run write evaluations
        if: steps.cli-check.outputs.available == 'true'
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          mkdir -p results

          # Build command
          CMD="python -m evals write-eval --verbose --output results --agent-cli ./bin/worldview"

          # Add models (write eval only supports Claude models)
          CMD="$CMD --all-models"

          # Add complexity filter if not 'all'
          COMPLEXITY="${{ github.event.inputs.write_complexity || 'all' }}"
          if [ "$COMPLEXITY" != "all" ]; then
            CMD="$CMD --complexity $COMPLEXITY"
          fi

          echo "Running: $CMD"
          $CMD

      - name: Upload write results
        if: steps.cli-check.outputs.available == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: write-eval-results-${{ github.run_number }}
          path: results/
          retention-days: 30

      - name: Post write summary
        if: steps.cli-check.outputs.available == 'true'
        run: |
          echo "## Write Evaluation Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          cat results/write_report.md >> $GITHUB_STEP_SUMMARY

      - name: Check write eval results
        if: steps.cli-check.outputs.available == 'true'
        run: |
          python -c "
          import json
          with open('results/write_results.json') as f:
              data = json.load(f)

          for model, info in data['models'].items():
              success_rate = info['summary']['success_rate']
              simple_rate = info['summary']['simple_rate']
              print(f'{model}: {success_rate:.1%} overall, {simple_rate:.1%} simple')

              # Simple cases should have high success rate
              if simple_rate < 0.6:
                  print(f'WARNING: {model} simple case rate {simple_rate:.1%} is below 60%')
          "
